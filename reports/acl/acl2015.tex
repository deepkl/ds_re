%
% File acl2015.tex
%
% Contact: car@ir.hit.edu.cn, gdzhou@suda.edu.cn
%%
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn,
%% based on the style files for ACL-2010, which were, in turn,
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2015}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Knowledge Graph Embedding with Transfer Learning on Biterm Topic Model of Entity Description}

\author{Qiang~Guo,Bingbing~Jiang,Liangang~Zhang,Huanhuan~Chen}

\date{\today}

\begin{document}
\maketitle
\begin{abstract}
  Knowledge graph embedding aims to encode both entities and relations into a continuous low-dimensional space.
  Most methods concentrate on the structure information of the knowledge graph whose nodes represent the entities and edges represent the relations between entities.
  In fact,there are usually concise text for entities,which can be modeled with topic model and well utilized by existing embedding methods.
  In this paper,we propose a novel method for knowledge graph embedding by uncovering the topics within the short entities descriptions and transferring the topic model to entity embedding.
  Specifically,we learn the topics by directly modeling the generation of word co-occurrence patterns in the whole entity description and transfer the topic model of the entity description to the knowledge embedding with transfer learning.
  We evaluate our method on two tasks,including knowledge graph completion and entity classification.
  Experimental results on Freebase show that,by special modeling the topic of the entity description and transfer learning,our method can significantly outperform state-of-the-art method.
\end{abstract}

\section{Introduction}

Hello World.


\section{Related Work}

Hello World.

\subsection{TransE}

Given a training set D of triples (h,r,t) composed of two entities h,t in E(the set of entities) and a relationship r in R(the set of relationships),TranE learns the vector embeddings of the entities and the relationships,by minimizing a margin-based ranking criterion over the training set:



\subsection{Biterm Topic Model}



\subsection{Tranfer Learning}

Hello World.

\section{Our Approach}

In this section,we introduce the transfer learning based TransE(TransT) that learns representations of entities and relations utilizing the topic model of short entity description.
In TransE and TransT,we have entity set \textbf{E} and relation set \textbf{R},and learn to encode both entities and relations in  R.
Given a KG represented by a set of triples S={(h,r,t)} with each triple composed of two entities h,t E and
their relation r R,there are also concise text for most entities in the KG.
We learn the topics by directly modeling the generation of entity co-occurrence patterns in the entities description corpora by Biterm topic model and transfer the topic model of the entity description to the knowledge embedding with transfer learning method.


\subsection{Transferring the Biterm Topic Model to Entities Embedding}
\label{sect:pdf}

From the task of Biterm topic model,we learn the topic distribution of entity description which can represent the semantic of the entities well.Each topic model of the entity can transfer to its embedding by the feature representation transferring method.

\begin{equation} 
h^*=h + \lambda\cdot o,
t^*=t + \lambda\cdot o
\end{equation}
\begin{equation}
L=\sum|h^*+r-t^*|
\end{equation}

\subsection{Training the Whole Knowledge Graph}
\label{ssec:layout}

Format manuscripts two columns to a page, in the manner these
instructions are formatted. The exact dimensions for a page on A4
paper are:

\begin{itemize}
\item Left and right margins: 2.5 cm
\item Top margin: 2.5 cm
\item Bottom margin: 2.5 cm
\item Column width: 7.7 cm
\item Column height: 24.7 cm
\item Gap between columns: 0.6 cm
\end{itemize}

\noindent Papers should not be submitted on any other paper size.
 If you cannot meet the above requirements about the production of
 your electronic submission, please contact the publication chairs
 above as soon as possible.

\section{Experiments}

Following ACL 2014 we will also we will attempt to automatically convert
your \LaTeX\ source files to publish papers in machine-readable
XML with semantic markup in the ACL Anthology, in addition to the
traditional PDF format.  This will allow us to create, over the next
few years, a growing corpus of scientific text for our own future research,
and picks up on recent initiatives on converting ACL papers from earlier
years to XML.

We encourage you to submit a ZIP file of your \LaTeX\ sources along
with the camera-ready version of your paper. We will then convert them
to XML automatically, using the LaTeXML tool
(\url{http://dlmf.nist.gov/LaTeXML}). LaTeXML has \emph{bindings} for
a number of \LaTeX\ packages, including the ACL 2015 stylefile. These
bindings allow LaTeXML to render the commands from these packages
correctly in XML. For best results, we encourage you to use the
packages that are officially supported by LaTeXML, listed at
\url{http://dlmf.nist.gov/LaTeXML/manual/included.bindings}





\section{Conclusion and Future Work}

It is also advised to supplement non-English characters and terms
with appropriate transliterations and/or translations
since not all readers understand all such characters and terms.
Inline transliteration or translation can be represented in
the order of: original-form transliteration ``translation''.



\section*{Acknowledgments}

The acknowledgments should go immediately before the references.  Do
not number the acknowledgments section. Do not include this section
when submitting your paper for review.

% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2015}

\begin{thebibliography}{}

\bibitem[\protect\citename{Aho and Ullman}1972]{Aho:72}
Alfred~V. Aho and Jeffrey~D. Ullman.
\newblock 1972.
\newblock {\em The Theory of Parsing, Translation and Compiling}, volume~1.
\newblock Prentice-{Hall}, Englewood Cliffs, NJ.

\bibitem[\protect\citename{{American Psychological Association}}1983]{APA:83}
{American Psychological Association}.
\newblock 1983.
\newblock {\em Publications Manual}.
\newblock American Psychological Association, Washington, DC.

\bibitem[\protect\citename{{Association for Computing Machinery}}1983]{ACM:83}
{Association for Computing Machinery}.
\newblock 1983.
\newblock {\em Computing Reviews}, 24(11):503--512.

\bibitem[\protect\citename{Chandra \bgroup et al.\egroup }1981]{Chandra:81}
Ashok~K. Chandra, Dexter~C. Kozen, and Larry~J. Stockmeyer.
\newblock 1981.
\newblock Alternation.
\newblock {\em Journal of the Association for Computing Machinery},
  28(1):114--133.

\bibitem[\protect\citename{Gusfield}1997]{Gusfield:97}
Dan Gusfield.
\newblock 1997.
\newblock {\em Algorithms on Strings, Trees and Sequences}.
\newblock Cambridge University Press, Cambridge, UK.

\end{thebibliography}

\end{document}
